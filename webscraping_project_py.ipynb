{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webscraping project.py.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuKn8YGuUNG0SxCk6aBrt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minjun5470/webscraping/blob/main/webscraping_project_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBV_3UEOJQk-",
        "outputId": "35114fdb-5b2c-4945-967c-ee5752bd2a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.10 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.10 wsproto-1.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[오늘의 날씨]\n",
            " 어제보다 3.1° 낮아요  흐림   체감 28.7° 습도 77% 바람(동풍) 2m/s  \n",
            " 현재 온도26.9° \n",
            "[미세먼지]\n",
            " 서울 27  좋음   좋음  \n",
            "[영어회화]\n",
            "영어 문장 가져오기\n",
            "Rob: Listen to that clapping. The audience likes him!\n",
            "Ms. Brown: Don’t you think Mr. Kim’s speech was too long?\n",
            "Rob: Well, yes, he did go over by 15 minutes, but I think everyone’s ready to forgive him for that. His speech was really informative.\n",
            "Ms. Brown: That’s true, but I may have to shorten my presentation so that we can stay on schedule.\n",
            "Rob: 박수소리를 들어보세요. 청중들이 그를 좋아해요!\n",
            "Ms. Brown: Mr. Kim의 연설이 너무 길었다고 생각되지 않나요?\n",
            "Rob: 음, 그러게요, 15분을 넘겼군요. 하지만 모든 사람들이 그런 그를 이해해주고 있는 것 같네요. 그의 연설은 정말 유익했거든요.\n",
            "Ms. Brown: 그렇긴 하지만 일정을 맞추기 위해서 제 발표는 짧게 해야겠어요.\n"
          ]
        }
      ],
      "source": [
        "#1.날씨 2.헤드라인 기사 3.해커스에서 매일 영어회화학습\n",
        "!pip install selenium\n",
        "\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from urllib.parse import quote_plus\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "\n",
        "def create_soup(url):\n",
        "    headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\"}\n",
        "    res=requests.get(url,headers=headers)\n",
        "    res.raise_for_status()\n",
        "    soup=BeautifulSoup(res.text,\"lxml\")\n",
        "    return soup\n",
        "\n",
        "print(\"[오늘의 날씨]\")\n",
        "url=\"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%84%9C%EC%9A%B8+%EB%82%A0%EC%94%A8\"\n",
        "soup=create_soup(url)\n",
        "cast=soup.find(\"div\",attrs={\"class\":\"temperature_info\"})\n",
        "curr_temp=soup.find(\"div\",attrs={\"class\":\"temperature_text\"})\n",
        "   \n",
        "print(cast.get_text())\n",
        "print(curr_temp.get_text())\n",
        "\n",
        "print(\"[미세먼지]\")\n",
        "url=\"https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EB%AF%B8%EC%84%B8%EB%A8%BC%EC%A7%80&oquery=%EB%82%A0%EC%94%A8&tqi=hWv8%2Flp0YidssE0sdXCssssssDh-069647\"\n",
        "soup=create_soup(url)\n",
        "pm=soup.find_all(\"tr\")[2]\n",
        "\n",
        "print(pm.get_text())\n",
        "\n",
        "#print(\"[헤드라인 뉴스-경제]\")\n",
        "#url=\"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=101\"\n",
        "#soup=create_soup(url)\n",
        "#e_news=soup.find(\"div\",attrs={\"class\":\"cluster_head\"}.find_all(\"\",limit=)\n",
        "#for index,news in enumerate(e_news):\n",
        "#    title=news.find(\"\").get_text().strip()\n",
        "#    link=url+news.find(\"a\")[\"href\"]\n",
        "#    print(\"{}.{}\".format((index+1),title))\n",
        "#    print(\"링크:{}\",format(link))\n",
        "\n",
        "print(\"[영어회화]\")\n",
        "url=\"https://www.hackers.co.kr/?c=s_lec/lec_study/lec_I_others_english&keywd=haceng_submain_lnb_lec_I_others_english&logger_kw=haceng_submain_lnb_lec_I_others_english\"\n",
        "soup=create_soup(url)\n",
        "sentences=soup.find_all(\"div\",attrs={\"id\":re.compile(\"^conv_kor_t\")})\n",
        "print(\"영어 문장 가져오기\")\n",
        "for sentence in sentences[len(sentences)//2:]:\n",
        "    print(sentence.get_text().strip())\n",
        "\n",
        "for sentence in sentences[:len(sentences)//2]:\n",
        "    print(sentence.get_text().strip())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}